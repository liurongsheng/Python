# 爬虫实例-图片下载基础版本

功能：根据标题下载图片到对应的文件夹
```
|   scrapy.cfg
|
+---images
\---ScrapyDemo
    |   items.py
    |   middlewares.py
    |   pipelines.py
    |   settings.py
    |   start.py
    |   __init__.py
    |
    +---spiders
            bmw.py
            __init__.py
```       

```python
## bmw.py
import scrapy
from ScrapyDemo.items import BMWItem
class BmwSpider(scrapy.Spider):
    name = 'bmw'
    allowed_domains = ['car.autohome.com.cn']
    start_urls = ['https://car.autohome.com.cn/pic/series-s33595/65.html']

    def parse(self, response):
        uiboxs = response.xpath("//div[@class='uibox']")
        for uibox in uiboxs:
            category = uibox.xpath("./div[@class='uibox-title']/a/text()").get()
            urls = uibox.xpath(".//ul/li/a/img/@src").getall()
            urls = list(map(lambda url:response.urljoin(url),urls))
            print(urls)
            item = BMWItem(category=category,urls=urls)
            yield item
            # 遍历 urls 给 lambda, 执行匿名函数
            # for url in urls:
                # url = "https://" + url
                # url = response.urljoin(url)
                # print(url)
```

```python
## items.py
import scrapy

class BMWItem(scrapy.Item):
    category = scrapy.Field()
    urls = scrapy.Field()
```

```python
## pipelines.py
import os
from urllib import request

class BMWPipeline(object):
    def __init__(self):  # 构造函数
        self.path = os.path.join(os.path.dirname(os.path.dirname(__file__)),'images')
        if not os.path.exists(self.path):
            os.mkdir(self.path)

    def open_spider(self, spider): # 开始运行爬虫的时候执行代码
        print("爬虫开始")

    def process_item(self, item, spider):
        category = item['category']
        urls = item['urls']

        category_path = os.path.join(self.path, category)
        if not os.path.exists(category_path):
            os.mkdir(category_path)

        for url in urls:
            image_name = url.split('_')[-1]
            request.urlretrieve(url,os.path.join(category_path,image_name))

```

```python
## settings.py
ROBOTSTXT_OBEY = False
DOWNLOAD_DELAY = 3

DEFAULT_REQUEST_HEADERS = {
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'en',
    # 'Referer': '',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36',
}
ITEM_PIPELINES = {
    'ScrapyDemo.pipelines.BMWPipeline': 100,
}
```
